what is microservice ?


all logic to one feature work correctly.



challenge : Data management between services

each service gets its own database.
services never will reach to each other dbs.


it is pattern : Database per service

we want run it independetly.





Sync and Async in microsevices :


Sync : services communicate with each other using direct request
       web of dependency



Async : Services communicate with each other with events. event based
        Event bus , each service emit events or receive events from event
        bus.


second way async communicate :
each service , one db.

how catch our need info from other serivces.

simontinously save to db and send event to Event bus. for any body care 
about it.




============================================================



Blog Post application :



============================================================


running service with Docker :


build with docker files and docker ignore files.

each service.


now we want use k8s

service: sth that give us access to running ads or running
container.

kubectl apply -f posts.yaml 

kind pod : it is object wrap up container.
metadata: config ooptions for object we are going to create.
spec : list of config options the pod that we are about to create. 


k get pods



deployment is a k8s object that is intended to manage set of pods.
 it check pods exists.
 use for update.


#      selector        says he k8s look at all pods with created with matchlabels param and watch it

in template labels define label for selector.


// many thing not saved like 70 lines



skaffold , 

==============================================


the big challenge is managing data :




async , 


STUBHUB


===========================================================


k8s cluster = nodes + matster for manage

node = a vm run our containers

pod = almost a running container technically

deployment = monintors set of pods, make sure they are.

service =  provide a easy remmebmer url to access other running container


---

k8s config files :

it say to k8s about objects (deployments , pods , services)

in yaml syntax

it is kind of documentation for cluster
allow others know what are you doing

create pod

create image 
define file
create with kubectl
kubectl apply -f nameoffile


about config :


apiVersion : api of object we want use it must contain set of objects

kind : type of object from api

metadata : config we want to apply to the object,
        options we want apply like name

spec : exact attributes we want our oject have, list of config options  

        containers : we can create many containers in a pod
                we add array of them here


run yaml file with  kubectl 

first build image\
push to hub
write yaml file for pod/deployment and service
use kubectl to build pod/deployment and service

kubectl apply -f posts.yaml
kubectl get pods

docker exec -it ... = k exec -it ...

k logs ... = show log of terminal for microservice


deployment is managar for pods
write yaml file for it.

spec : how deployment must behave

in spec section of deployment
selector says he k8s look at all pods with created with matchlabels param and 
watch it for me

when use deployment if we delete pod or any problem , deployment will 
generate new one

k describe deployment 
k logs [pod name]
check event






for update deployment :
there are ways for this .
1 : update image in hub. update image version in yaml.
    now must inform k8s. k apply -f file.name -> show configured.
    (not good to change that number each time)
2 : use latest tag on image or leave it off. update code . build image .
    push to hub . then use command
    k rollout restart deployment [depl name]






now services :
by services we allow to use our pods (before it is hidden)
service is object. default type is ClusterIp.
4 type ClusterIp (expose pods only in cluster) and 
       loadBalancer(outside w) for daily use
       nodeport (dev outside w) 
       externalName (redirect to c name)





in spec/selector of serivce we put name of pod we want expose to world

port listen on LVM (also allow access out world).
targetPort listen on our piece of app.


nodePort(browser) -> port(NodePort service) -> targetPort(pod)

[minikubei ip]:[nodePort]/${route}





write services in one file
hint : ClusterIp services exists with NodePort or loadBalancer at same.

hint hint : use k explain pods or services so cool




how communicate between serivces???
change name of route in axios or what ever to name of
http://[ClusterIp service name]:[port(other ClusterIp)]/[route you defined]
(this case is when you have not famous message broker)




loadBalancer service :

cra go in pod.
in spa case all req come to pods from browser.
therefore we must only serve static files.

but how cra connect to others

cra --> loadBalancer service ->> it connect to all ClusterIp s

now make sure cra connect to it 
and make yaml for loadBalancer





loadBalancer service : tells k8s to reach out to its provider and provision a 
        loadBalancer . get traffic to single pod
        (do it in front with nginx)
        cluster is in cloud provider we want out world traffic in.
        make config for it . feed to cluster 
        it says to our cluster go and reach out to our cloud provider
        and provision sth called LoadBalancer
        it exists outside cluster in cloud provider - part of google or aws


Ingress or Ingress Controller : a pod with a set of routing rules to distribute traffic
        to other service.
        (do it with ingress-srv)
        it work along side top service and give it rule of routing to choose best
        pod 



outside(react browser)-> loadBalancer(cloud)-> cluster(ingress(rule routes)-> srv.pods)





we use ingress-nginx (check github) 
ingress-nginx = create both loadBalancer  +  Ingress

also there is another kubernetes-ingress

go website -> deployment -> installitaion guide


run mandatory command (give u yaml)
for this add  ingress from his website or addons enable minikube

provider specific command (give u yaml)
for this define yaml
{
        kind: Ingress
}

annotations : help ingress Controller understand we try to feed him some rules 
so ingress continusly scan objects and try to find someone who has below annotaions
kubernetes.io/ingress.class: nginx

nginx have some rule for me
allow us use regex

spec:
        rules : teach ingress here
        define host : [posts.com]
               http
                 paths
                   path
                   backend
                     serviceName
                     serivcePort




with k8s and his cluster we can host many sites 
we trick our machine to conect local host go to posts.com
edit -> /etc/hosts add [minikube ip] [name of host you want]



Now CRA :
change rotue to posts.com
make yaml file for react

last step :
add rules to ingress service
ingress can not do routing base on Method of request










To update and change env in dev env we use automate tool
https://stackshare.io/skaffold/alternatives
can use helm or other in prod




skaffold :
automate task in k8s
you can not use in prod

can change set of objects quickly.


create yaml file for it in root of all proj

when stop it delete all objects.
local/push : false prevent it to push and build image to docker hub
on each save

artifacts:  array of each image with their config
        if change is not in manual path , skaffold rebuild image
        like changes in package.json



to start
skaffold dev 


must always use to nodemon to make changes.

sometimes detecting not change we fix it in future.


----------------------------

NExt Project :

big challenge is data ,
we use async communication (with message brokers) with events
with async every service is self sufficient 100%
we use k8s for scale and deploy

we build npm to share code - central lib for share services
must define all our events in our library to know what happen
we also handle concurrency


overview of app :

STUBHUB

user collection , tickets collection ,  order collection , charge


we have 5 services

auth, tickets , orders , expiration , payments


events and architecture :
userCreated, userUpdated ... OrderCancelled , OrederCreated , ...
ticketCreated , chargeCreated ...


client(nextjs)-->
common (shared lib) -->
microservices with mongo , redis -> 
nats streaming server

----

auth service start 

install dependencies

tsc --init 

create src

index.ts

simple server 

now start k8s infrastructure from start

make docker file
make docker ignore file

build image
docker build -t penkong/stubhub-auth .

make infra/k8s folder 

wrtie auth-deployment with ClusterIp service

make skaffold - it read from local
(deploy section load all yaml file we want
in sync manual dest: . means where to sync file to inside running container
get file from src and through it container
)

start minikube

skaffold dev (if not reload use this in package ts-node-dev --poll src/index.ts)


now we want access our service
now set up ingress-nginx (loadBalancer --> ingress Controller)


make it available in minikube or server


write yaml for nginx - define domain
browsers does not trust ssl from server 
type anywhere in tab thisisunsafe

-------------------------

SECTION GO TO GOOGLE CLOUD :
need card
two way 

1 . by add sync section in skaffold.yaml new config 

2 . now when we change unsynced file --> skaffold got google cloud build 
    --> upload image to google cloud vm

now go through setup

cloud.google.com/free --> go sign up

create project -> go to project -> kluster engine -> cluster
create cluster -> setting 

kubectl context to connect to google cloud
kubectl use context as connection settings

to add context 2 way in gcloud dashobard or use google cloud sdk

sdk -> cloud.google.com/sdk/docs/quickstarts

install 

terminal  -> gcloud

gcloud auth login

init -> gcloud init

choose 

setup context now 

with docker running 
gcloud container clusters get-credentials <cluster name = ticketing dev>


now update skaffold config

enable gcloud build -> tools -> cloud build
update yaml -> after config -> change image name in deployment also
setup ingress-nginx on gcloud cluster -> command from website 
update hosts file to point there -> get loadBalancer ip from google ->
        network service -> get ip of loadBalancer -> add to /etc/hosts
restart skaffold


---------------------------------------------------

Section 7 : response normalization response

let go for auth proj

define router 
use them 
use express-validator to validate and sanitazation body of req
        add array az middleware validator with body()

import type of req, res
make route complete

but we need same error response for all of error back from all services
need similar structure for error

we make middleware for error, use it in app , throw error from router ,
refine error on middleware 

we define subclass of error for any reason.

created costum handler and use it by middleware

give type to class and error message return 

finally we used abstract class to make error to use

-----------------------------------

Section 8 : database modeling 

install mongoose 

each service has own db

express app => mongoose <=> mongoDb instance with deployment and clusterIP

with skaffold crete it

lifecycle of pods : if we delete pod of mongo db we lose 
how solve ? we back here 

we register mongoose with start() function style

now model and signup flow 
questions : 

req
1 . does user already exists?
2 . do we hash password when user enter?
3 . create new user and save to db
4 . send back jwt token for user logged in
res

why mongoose and ts have problem with each other???
because name of collection and docuemnt is same .
ts don't understand of prop pass to new User({here})
docuemnt make change must teach ts about it



create user model

to be sure of info pass to model , 
creat interface in model

use custom function for build model with ts
like this userSchema.statics.build

but ts does not understand how attach func to object

there fore need make new interface that desc the prop user model have

new interface extends mongoose.Model and we attach build() to it


now must fix second proble of when model create is different from 
what back from mongo

we do new interface that describe info come back from model 

and put it as first type(generic) in model and also response of  build()

generic : functions for types, args for function model


now signup process

check with findOne user exist
define new error for it

hash pass step
use for signup and signin
hash password -> produce unique string for that pass
we do hash stuff in model but because keep things clean
we do login in seprate class and only consume it there.
make services folder -> for general purpose things
when we want save user a lifecycle(middleware) 
from monog call presave and
do hashstuff
and in that middleware you must call done()

we use scrypt from crypto (it is hashing function)
use promisify with scrypt
scryptAsync bring us back a buffer

create user
save
return user (jwt in future)


------------------------------------------------

Section 9 : authentication 

this is so challenging part

there are many approaches 

main question : is this person logged in???

option 1 : 
sync requetst to auth serivce (centralize auth service)
but if auth service go down ???  - down side 



options 1.1 : 
every request go through single gateway that would authenticate
the incoming request -> then go to relate service
but if auth service go down ??? - down side


options 2 :
teach each individual serivce how to authenticate a user
each contain logic to inspect jwt/cookie and decide 
no dependency to out service 
duplicate logic of auth - down side  -> use share library
more down side : if other serivce make user invalid how other know?


we go with option 2 because we want independet services


let's do it :

make cookie for 15 minutes

if token is old( 30 min ) -> from logic inside service -> goto auth service
--> it give us refresh token 

or after (15 min) we say to user go to auth service and get new token

if we want ban user -> send event to ban user 



reminder cookie and jwt :
header 
        Set-Cookie : value  -> auto store to browser 
        browser send it with 
        request in 
header 
        Cookie : value


payload --> jwt algorithm --> jwt

we can put jwt on -> request header with Authorization 
                             body token
                             header Cookie


cookies are transport mechanism , move any kind of data , auto manage
        by browers

JWT auth/authorization mechanism , store any data we want , 
        we have to manage it manually 


our system need after authentication , send us info about user accesses
or buy power or ... , roles , accesses , expiration , diff language


on request we verify user authentication 

we use nextjs - ssr 
nextjs go to get info to generate ssr info therefore all auth 
do in server 
we need to know auth info from first reques because next do things
on server base on info came from server 

therefore we can not intercept request to attach Authorization to header
or there is not any body request




browser must send -------    jwt on Headers with Cookie
(service worker can work here)


we use cookie-session because let us store info in cookie by itself     


we want be sure content of cookie understand by differenet languages
and cookie-session use crypto 
what we do?
we not encrypt cookie

add cookie-session and types 

use it with options 

change setting on express itself

app.set('trust proxy' , true);

because traffic is proxied to our app through ingress-nginx
and express i dont like it . express let it happen


now everything ok , we must generate jwt and set it to cookie 
consider cookie-session do all other things

we store some info inside cookie by 
req.session
it is object created by cookie session 


npm i jsonwebtoken

by jwt.sign() we create > jwt
arg 1 : payload -> info we want store in jwt
arg 2 : signkey -> our secret


by jwe.verify() we become sure nobody change jwt
also use draw out payload


after save user to db we generate jwt with sign
hint : must save secret to k8s guys


then set it on req.session 

it save on base64 encoded
first decode base on 64
and after that you will see jwt

it have payload inside it , 


now sign key : 
now when we recive that jwt inside another service we need jwt sign
key -> but it bad because other can change -> but we must exchange it
it profession way

storing secrets with k8s

it have feature for it




we create new type of object inside cluster
object secret
when we create it we can use it inside node / pods as env var



create secret
kubectl create secret generic jwt-secret --from-literal=jwt={'hree'}
                          name of secretobj      assign key=value
generic is kind of secret , there are kinds for it
also secret like access image in docker repo


k get secrets


now must store in inside pod as env -> deployment

in containers -> add env / name : name of var as it show inside container
JWT_KEY

kubectl create secret generic jwt-secret --from-literal=JWT_KEY=123456asdf
       -name: JWT_KEY
        valueFrom:
          secretKeyRef:
            name: jwt-secret
            key: JWT_KEY



now want access it from code :
process.env.JWT_KEY!


to keep gaurd exist of env we must do it on init
on start 
if (!process.env.JWT_KEY) throw new Error('JWT_KEY MUST BE DEFINE')





now we must common response props 
like errors :

we do it in model with projection like 

on schema / second arg / toJSON : { transform(doc, ret) {}}
check code



NOW SIGN IN ROUTE :
steps like sign up at first


draw out validation stuff and make it middleware
base on args on middleware express understand type of middleware
when it is 4 it get it is error middleware

we now dont capture error (like error handler middleware) 
we produce error here

this validateRequest use over almsot every put and post request

check exist of user
if exist
compare password
if ok
generate jwt
and ...


current user :
react can not look at cookie
can not be access 
therefore we must somehow provide

if no cookie -> send current user null

check valid cookie token

if exist -> send current user from verify cookie
jwt.verify()
because it throw error we must use trycatch


we will add authorization stuff as middleware in near future


signout : 
req.session = null



now we need currentUser middleware :
when request come to other services
we want to know user is logged in or not or exist

and we add currentUser to request 
that let that service consume info of user from req
and dont need use jwt to decode 
decode and verify in middleware
register info on req -> service consume it

hint :
!req.session || !req.session.jwt == !req.session?.jwt


to add prop to exist object (req.currentUser)

we want augment it 
// to add new prop to it
declare global {
  namespace Express {
    interface Request {
      currentUser?: IUserPayload
    }
  }
}



second middleware reject if not user.
only check req.currentUser if not extist throw error



-------------------------------------------------

Section 10 : testing isolated microservice
what our test scope???

test a single code in isole like middleware(unit test) 

or

test how different piece of code work like req flow throuh middleware and
handler 

or 

test how differenet component work like request to service ensure write
to database or eventbus  

or

test how differenet service work like create a payment that have impact
on multi microservice ----> not now - not here


we do test microservice in isolation


test goal :

1. basic request handling -> test whole microservice *****

2. some test around model -> unit test like -> like test model

3. event emitting and receiveing -> send and receive evetns ->
it is like simulating service works together.


HOW WE EXEC TEST AT ALL ???
for now with npm run  but we go through more complex




TESTING ARCHITECTURE :

we implemet testing goal 1 

jest - test runner lib

steps:
start in momory copy of mongo
start express
use supertest lib to make fake request --> need some refactor
  we must have access to express app 
  we need to it , 
  but there are a lot of stuff there
  and also maybe port is in use by another (jest run concurrently)
  supertest if it not listen -> goto ephemeral port (random available)
  therefore we must not listen on 3000
  and split index to 2 file
  app.js -> express app not listen on any port
  export to test(ephemeral) and also to index.js(3000)
run assertion to make sure things right



do refacotr ot app.ts and index.ts


also we use mongodb-memory-server 
it allow us to run multiple mongo at same time

it is huge to prevent from dl on docker image add to 
npm install --only=prod


now add script 
test": "jest --watchAll --no-cache",
no-cache because of typescrpt

add "jest" field to packge.json

setup files after env , by this we tell jest run setup files after we initially 
start our test

add setup related stuff for mongo and other stuff


create mongo memory server allow us run differenet suites test at same time
let us direct access to 
get uri
pass to mongoose 

now before each test we reach to mongo and delete all data related

after all test done we stop server and close connections


NOW TEST :

for each folder in your service make __test__ folder for let jest know

signup .test.ts

use
supertest to make fake request to exprss app
request use chain syntax

npm run test

but we got error because in our test we dont have access to env vars

add to setup   process.env.JWT_KEY = '123456asdf'

ts maybe have problem with jest just restart it.

not test with wrong input

hit enter to run test

can write 2 seprate requetst insdie test with await request
does not matter you must either do await or return request


unique test email

inspect header has cookie set 
res of signup has get method that have access to header
but test failed 
because cookieSession share cookie if request come from https

but supertest do http
when jest run make NODE_ENV to test
secure: process.env.NODE_ENV !== 'test'

we can continue many test


signin test suites :
normal test


signout also test suite 

currentUser test suite 
test env like browser and postman have not ability to send cookie with request
therefore currentUser is null , how fix it???


two way easy and refacotr way

get cookie from signup attach it to currentUser
get it 
include next request with chain .set('Cookie', authResponse)
res.body.currentUser.email

but because it is repetetive
we use signup as helper function


write it in setup.ts as global function attached to all test


test for model and event handling will come in future.


--------------------------------------------------------


SECTION 11 : intergrate react ssr with nextjs

we build auth section of react app in this field


we do stuff on server

browser requets to => nextjs server => goto take data => 

i react react-dom next`

dev : next
 
add files you need 

add docker file

add kuberfile you need

add ingress config

add skaffold config



























































